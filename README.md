# Attacking ML Classifier with Adversarial Images 

--- 
Create adversarial images that can be used to fool to misclassify MNIST data in a deep convolutional neural network. 
 

![alt text](http://karpathy.github.io/assets/break/breakconv.png "Example of a panda being misclassified by a neural network. [2]")



## Prerequisites 
* Python 3.3 +
* Tensorflow 1.1.0
* matplotlib 2.1.0
* numpy 

## Related 
* [1] [TensorFlow's 'Deep MNIST for Experts' guide](https://www.tensorflow.org/get_started/mnist/pros#deep-mnist-for-experts)  
* [2] [Goodfellow's 'Explaining and Harnessing Adversarial Examples'](https://arxiv.org/pdf/1412.6572.pdf)
* [3] [Andrej Karpathy's 'Breaking Linear Classifiers on ImageNet'](http://karpathy.github.io/2015/03/30/breaking-convnets/)
